# Deliverable, Orthogonalization and Iteration

Yang Xi<br>
30 Sep 2020

<br>

* Introduction
* Project Deliverable
* Orthogonalization
    * Chain of Assumption in ML
* Model Iteration
* References

<br>

<br>

## Introduction

A machine learning project usually starts with understanding the business problem.<br>
Here I will highlight several aspects which I highly emphasized at the start of a project.

<br>

## Project Deliverable

It's important to keep the final deliverable in mind since the beginning.<br>
The following questions will help understanding the problem and structuring the deliverable:
* What is the **existing solution**?
    * The stakeholders must have been doing something to tackle the problem before they embarking machine learning.<br>
    These will help you understand the problem better, even be a good benchmark!
* **Who/what system** will consume the output?
    * If the model output will provide information for stakeholders to support decision, usually it needs to present the following properties:
        * Highly interpretable
        * Can be ranked in some way: there may not be enough resource for human to consume all outputs.
    * If the model output is automated to drive a downstream decision-making system:
        * The design will be more around engineering capability
        * It still needs some pipeline to collect usage and actual performance
* How **frequently** is the output consumed?
    * This will directly affect the granularity of your data, sampling strategy, as well as pipeline design.
* What is the **resource constraint**?
    * For example, if there is not enough resource to consume all outputs, the problem may turn into a **ranking problem**.<br>
    In this case, the overall performance of the model is not that important, while it matters more whether the model can highlight the top N observations properly.
* How to **deploy** the model?
    * This includes the **inferencing** pipeline, as well as the **model monitoring** pipeline.

<br>

## Orthogonalization

Once you understand the business problem, there are way too many directions to pursue and concerns to address.<br>
**Orthogonalization** is a mindset which allows you to focus on handling one perspective at a time.

### Chain of Assumption in ML
Let's use the **chain of assumptions in ML** to illustrate the idea of orthogonalization.

There are 4 types of errors in the chain of assumptions in ML. The orthogonalization measures will focus on addressing **only one** type of error.<br>
Some examples are listed under each line:
1. Fit training set well (approximating/surpassing human level performance)
    * To address training (avoidable bias) error: more complex model, better optimization, ...
2. Fit dev set well
    * To address dev (variance) error: regularization, bigger training set, ...
3. Fit test set well
    * To address test error: bigger dev set, ...
4. Performs well in real world
    * To address real-world error: change dev & test set, change cost function, ...

On the other hand, a **non-orthogonal** measure would be early-stopping, which generally affects the training and dev errors simultaneously. This is not "bad", but it can make the problem more complex where you addressed one issue but raised another.

Orthogonalization is not limited to address model errors. This mindset will be applied throughout the markdowns.

<br>

## Model Iteration

With the orthogonalization mindset, we can focus on building our first system quickly:
1. Setup dev and test set and performance metrics
2. Build the initial system quickly
3. Use bias/variance analysis and error analysis to prioritize next steps

Details of these steps will be discussed in other markdowns.

<br>

## References
* [(2020 Andrew Ng) Structuring Machine Learning Projects](https://www.coursera.org/learn/machine-learning-projects)
* [(2013 Foster) Data Science for Business](http://www.data-science-for-biz.com/)
