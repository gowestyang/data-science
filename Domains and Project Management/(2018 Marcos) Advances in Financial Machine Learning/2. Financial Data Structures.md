# 2.1 Motivation
It is better to start from unstructured / raw data, instead of other people's processed dataset, to be able to indentify informative features first.

<br>

# 2.2 Essential Types of Financial Data
## 2.2.1 Fundamental Data
Accounting data: regularized, low frequency, very accessible to the marketplace
* Reported with a lapse
    * A **frequent error** is to assume that the data was published at the end of the reporting period
    * Make sure your analysis uses information only after it was publicly available
* Backfill missing data / reinstate (correct) value
    * The corected values were not known on that first release date

<br>

## 2.2.2 Market Data
All trading activities
* Ideally, you have the raw feed with unstructured information, like FIX messages
    * Not trivial to process
    * Abundant data volume

<br>

## 2.2.3 Analytics
Derived data based on original source (fundamental, market, alternative, other analytics, etc)
* Research reports
* Derived statistics
* Can be costly, and you are not the sole consumer

<br>

## 2.2.4 Alternative Data
Unique and hard-to-process datasets (which makes them promising)
    * Producted by individuals: news, social media, etc
    * Business processes: transactions, corporate data, government agencies, etc
    * Sensors: satellites, geolocation, etc
Alternative data can be **primary information** ahead of other data sources.
    * Cost and privacy concerns

<br>

# 2.3 Bars
Finance practitioners often refer to information extracted and represented in table as "bars".

<br>

## 2.3.1 Standard Bars
A homogeneous series derived from regular sampling, usually offered by data vendor's API

<br>

### 2.3.1.1 Time Bars
* Sample information at fixed time intervals, such as volume-weighted-average-price (VWAP), open/close/high/low price, volume traded
* Shold be avoided for two reasons
    * Markets do not process information at a constant time interval: time bars oversample information during low-activity periods, and undersample information during high-activity periods
    * Exhibit poor statistical properties, such as serial correlation, heteroscedasticity, no-normality of returns

<br>

### 2.3.1.2 Tick Bars
* Sample statistics over every pre-defined number of transactions
    * Synchronize sampling with a proxy of information arrival
    * Exhibite desirable statistical properties; allow returns closer to IID Normal
* Beaware of outliers, such as auction trade
* One problem caused by order gramentation: trades vs. transactions, partial fills

<br>

### 2.3.1.3 Volume Bars
* Sample statistics over every pre-defined units have been exchanged
* Achieve better statistical properties than tick bars
* Support analysis between price and volume

<br>

### 2.3.1.4 Dollar Bars
* Sample statistics over every pre-defined market value has been exchanged
* Particularly usefuly in analysis involving significant price fluctuations
* More robust in facing corporate actions which change the number of outstanding shares, such as splits and reverse splits
* Can apply dynamic bar size: as a function of the free-floating market capitalization / outstanding amount of issued debt

<br>

## 2.3.2 Information-Driven Bars
Sample more frequently when new information arrives.

<br>

### 2.3.2.1 Tick Imbalance Bars (TIB)
* Monitor percentage of delta price between ticks
* Sample bars whenever "tick imbalances" exceed our expectations
* Sample buckets of trades containing "equal amounts of information", and more frequently under the presence of informed trading

<br>

### 2.3.2.2 Volume/Dollar Imbalance Bars (VIB/DIB)
* Extend the concept of Tick Imbalance Bars (TIB) - sample bars when "volume / dollar imbalances" diverge from our expectations
* Address concerns regarding tick fragmentation, outliers, corporate actions
* Adjust bar size dynamically

<br>

### 2.3.2.3 Tick Runs Bars (TRB)
* Large traders will sweep the order book with iceberg orders
* Monitor the sequence of buys in the overall volume
* Take samples when the sequence diverges from our expectations

<br>

### 2.3.2.4 Volume/Dollar Runs Bars (VRB / DRB)
* Extend Tick Runs Bars (TRB) to volumes and dollars exchanged
* Sample bars when the volumes / dollars traded by one side exceed our expectation

<br>

# 2.4 Dealing with Multi-Product Series
We can face some challenges when modelling a time series of interuments, where the weights need to be dynamically adjusted over time. Such as
* Products that pay irregular coupons/dividends, or subject to corporate actions
* Baskets of securities where dividends/coupons are re-invested
* Baskets of securities are rebalanced, or index's constituents are changed
* Replace an expired/matured contract/security with another
* Roll of futures

<br>

## 2.4.1 The ETF Trick
Say, to develop a strategy to trade a spread of futures, there are a few nuisances:
* Spread is characterized by a vector of weights that changes over time
* Spreads can be negative values, which can be problematic to many models
* Trading times may not aligh exactly for all constituents -- latency risk and execution cost

One solution is to product a time series that reflects the value of $1 invested in a spread, as if an ETF (a single non-expiring cash product)
* Changes in this series will reflect changes in PnL
* This series will be strictly positive

<br>

## 2.4.2 PCA Weights
Use PCA to compute hedging weights

<br>

## 2.4.3 Single Future Roll
The ETF trick can handle the rolls of a single futures contract (1-legged spread). While a more direct approach is to
* Firstly, form a time series of cumulative roll gaps
* Then detract the gaps series from the price series
* Note the rolled prices can possibly become negative

<br>

# 2.5 Sampling Features
Sample data to build ML models

<br>

## 2.5.1 Sampling for Reduction
Downsampling
* Linspace sampling: sequential sampling at a constant step size
* Uniform sampling: sampling randomly using a uniform distribution

<br>

## 2.5.2 Event-Based Sampling
Let ML algorithm learn whether there is an accurate prediction function under some events, such as
* structural break
* extracted signal
* microstructural phenomena

<br>

### 2.5.2.1 The CUSUM Filter
("cumulative sum") A quality-control method to detect a shift in the mean value of a measured quantity, away from a target value.
* CUSUM filters can avoid triggering multiple events if the time series is hovering around the threshold level, which is a flaw suffered by some popular signals such as Bollinger bands.
