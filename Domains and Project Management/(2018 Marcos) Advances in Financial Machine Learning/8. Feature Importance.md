# 8.1 Motivation
One of the **most pervasive mistakes** in financial research is to take some data, run an ML algo, backtest the predictions, and repeat until a nice-looking backtest shows up.
* It does not matter if the backtest is a walk-forward out-of-sample
* Repeating a test over and over on the same data will lead to a false discovery
    * It typically takes about 20 such iterations to discover a false strategy.
    * Feature importance offers an alternative

<br>

# 8.2 The Importance of Feature Importance
It is very easy to overfit a backtest. Feature importance must be analyzed before any backtest is carried out.
* What features are important?
* Are these features important all the time?
* What triggers a change in importance? Can such changes be predicted?
* Are these important features also relevant to other related financial instruments or asset classes?

<br>

# 8.3 Feature Importance with Substitution Effects
Substitution effect takes place when the importance of one feature is reduced by the presence of other related features.
* Substitution effect can lead us to discard important features that happen to be redundant.
* This is not generally a problem in the context of prediction.
* It could lead us to wrong conclusions when understanding / improving / simplifying a model.

<br>

## 8.3.1 Mean Decrease impurity (MDI)
MDI is a fast, explanatory-importance (in-sample) method specific to tree-based classifiers, such as RF.
* Rank features by the overall impurity decrease
* MDI can be computed on the fly, with minimum computational cost.
* As the procedure is in-sample, features without predictive power will also get some importance.
* Cannot be generalized to non-tree based models
* Be aware of **masking effect** - some features can be systematically ignored by tree-based classifier
    * Set `max_features` to 1 to give every feature a chance to reduce impurity.
    * Make sure you don't average feature with 0 importance, because "0" means the feature was not randomly chosen.
* MDI is implemented to have the feature importances **add up to 1**, with every feature importance between 0 and 1
* MDI **cannot address substitution effects** of correlated features - the importance of two identical features will be halved

<br>

## 8.3.2 Mean Decrease Accuracy (MDA)
MDA is a slow, predictive-importance (out-of-sample) method.
* Steps
    * Fit a classifier
    * Derive the out-of-sample performance score (accuracy, negative log-loss, etc)
    * Permutate each feature, one at a time, to derive the out-of-sample performance again
    * The importnace of a feature is a function of the loss in performance
* MDA can be applied to **any classifier**
* MDA also **cannot address substitution effects** of correlated features - the importance of two identical features will be both irrelevant
* It is possible that MDA concludes all features are unimportant
* Importance of a feature can be negative

<br>

# 8.4 Feature Importance without Substituion Effects
## 8.4.1 Single Feature Importance
SFI is a cross-section predictive-importance  (out-of-sample) method. It simply computes the out-of-sample perofrmance of each feature in isolation.
* SFI can be applied to any classifier
* No substituion effect, because only one feature is considered at a time
* It is possible to conclude all features are unimportant
* The main limitation is that, a classifier with two features can perform better than the bagging of two single-feature classifiers.

<br>

## 8.4.2 Orthogonal Features
To reduce substituion effects of MDI and MDA, a partial solution is to orthogonalize the features before applying MDI / MDA.
* Orthogonalization such as PCA will not totally remove substitution effects, but can alleviate the impact of linear substitution effects
* Remember to scaling the features before PCA

Orthogonal features also provides other benefits:
* Reduce the dimensionality of feature space to speed up convergence
* Address the risk of overfitting
    * PCA is unsupervised learning, without using knowledge of the labels
    * Training model on PCA result can **prevent totally overfitting**
    * If MDI / MDA / SFI analysis selects most important feature as the PCA principals, this is an evidence that the model is not entirely overfit
        * It is useful to compute the weighted Kendall's tau between the feature importances and their associated eigenvalues (inverse PCA rank)

<br>

# 8.5 Parallelized vs Stacked Feature Importance
* Feature importance in parallel
    * From a basket of instruments, derive feature importance from each instrument
    * Features that are important across a wide variety of instruments are more likely to be associated with an underlying phenomenon
    * Note that due to substitution effects, important features may swap their ranks across instruments.
        * This disadvantage can be alleviated with a sufficiently large instrument basket

* Feature importance by stacking
    * Stack all datasets into a single combined dataset
    * Let the classifier learn feature importance across all instruments simultaneously
        * No need to further combine the results as in the parallel way
        * Less prune to outliers, overfitting or substituion effects
        * Consume more memory, as you need to process all instruments in one-shot
