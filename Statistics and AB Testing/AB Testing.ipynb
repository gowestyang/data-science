{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AB Testing\r\n",
    "Yang Xi <br>\r\n",
    "20 Aug, 2021"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\r\n",
    "*Reference: https://vwo.com/ab-testing/#a-b-testing-challenges*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Iterative Process of A/B Testing\r\n",
    "- Research\r\n",
    "- Logging Observations\r\n",
    "- Formulating Hypothesis\r\n",
    "- A/B Testing\r\n",
    "- Deploying the Wining Version\r\n",
    "\r\n",
    "<br><br>\r\n",
    "\r\n",
    "## Frequentist vs. Bayesian\r\n",
    "### Frequentist\r\n",
    "- Use only data from current experiment\r\n",
    "- Estimate mean and standard deviation\r\n",
    "\r\n",
    "### Bayesian\r\n",
    "- Incorporate prior knowledge from the previous experiments\r\n",
    "- Possibility of A beating B, as well as range of the expected improvement\r\n",
    "\r\n",
    "<br><br>\r\n",
    "\r\n",
    "## Challenges\r\n",
    "- Decide **what to test**\r\n",
    "- Formulate **hypothesis**\r\n",
    "- Determine **sample size** (or test duration)\r\n",
    "- **Interpret** test results – why a variation stood out?\r\n",
    "- Maintaining a **testing culture** – A/B testing is iterative\r\n",
    "\r\n",
    "### Type I and Type II Errors\r\n",
    "- Type I: False Positive – it seems significant but actually not – usually more severe\r\n",
    "    - Cannot be totally avoided – use at least 95% confidence level (at most 0.05 significance level / p-value)\r\n",
    "- Type II: False Negative – it seems not significant but actually is – discouragement\r\n",
    "    - Improve statistical power (at least 0.8) – more samples, fewer variants, etc\r\n",
    "\r\n",
    "<br><br>\r\n",
    "\r\n",
    "## Common Mistakes & Key Notes\r\n",
    "- **Invalid hypothesis** will make the test unlikely to succeed.<br>\r\n",
    "This could happen if you take other’s success story, without analyzing your own data.\r\n",
    "- Testing **too many elements** together makes it difficult to pinpoint which element influenced the test’s success/failure the most.\r\n",
    "- You should focus on statistical significance, but not personal **opinions or gut feelings**.\r\n",
    "- **Unbalanced traffic** will increase the chance of failure.\r\n",
    "- Both **running too long or too short** can result in failure.\r\n",
    "- Try not to **change your experiment** settings / goals / designs in the middle of a test\r\n",
    "- A/B testing is an iterative process. Do not **stop testing** after the first success / failure.\r\n",
    "- Tests should be run in **comparable periods**.\r\n",
    "\r\n",
    "<br><br>\r\n",
    "\r\n",
    "## Scale Up A/B Testing\r\n",
    "- When doing many tests\r\n",
    "    - Ensure none of the tests affect others or the overall (website’s) performance.\r\n",
    "    - No more than two tests overlap each other at any given week.\r\n",
    "- More sophisticated testing methods\r\n",
    "    - Split URL testing\r\n",
    "    - Multivariate testing (MVT)\r\n",
    "    - Multipage testing\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Distributions and Hypothesis Testing\r\n",
    "\r\n",
    "Should A/B testing use **one-tailed or two-tailed tests**? <br>\r\n",
    "This article provides some debates: *https://blog.analytics-toolkit.com/2017/one-tailed-two-tailed-tests-significance-ab-testing/*\r\n",
    "\r\n",
    "<br>\r\n",
    "\r\n",
    "*More Reference:*\r\n",
    "- *https://en.wikipedia.org/wiki/A/B_testing*\r\n",
    "- *https://towardsdatascience.com/required-sample-size-for-a-b-testing-6f6608dd330a*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definitions\r\n",
    "*Reference: https://machinelearningmastery.com/statistical-power-and-power-analysis-in-python/*\r\n",
    "\r\n",
    "* p-value vs. Significance Level (α)\r\n",
    "    * **p-value (p)**: Probability of obtaining a result equal to or more extreme than was observed in the data.\r\n",
    "    * **Significance Level (α)** = Boundary for specifying a statistically significant finding when interpreting the p-value.\r\n",
    "        * Commonly selected at α = 0.05\r\n",
    "        * 5% likelihood to encounter **Type I Error**\r\n",
    "    * Reject the Null Hypothesis H0 if p <= α\r\n",
    "\r\n",
    "<br>\r\n",
    "\r\n",
    "* **Statistical Power (sensitivity)**: The probability that the test correctly rejects the null hypothesis.\r\n",
    "    * Power = 1-β\r\n",
    "    * β = **Type II Error** (false negative)\r\n",
    "    * Commonly selected at Power = 0.8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import scipy.stats as ss\r\n",
    "import statsmodels.stats.api as sms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Distribution\r\n",
    "Gaussian Distribution can be observed in data like **\"Average reveneue per user\"**.\r\n",
    "- **Null hypothesis**: two means are equal (m1 = m2)\r\n",
    "- **Welch's t-test** (standard): designed for comparing two normally distributed populations with **unequal variance**. \r\n",
    "- **Student's t-test** (alternative): designed for comparing two normally distributed populations with **equal variance**. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "np.random.seed(0)\r\n",
    "ar1 = np.random.normal(loc=0.15, scale=0.05, size=90)\r\n",
    "ar2 = np.random.normal(loc=0.18, scale=0.05, size=90)\r\n",
    "\r\n",
    "t_Welch, p_Welch = ss.ttest_ind(ar1, ar2, equal_var=False) # default to two-tailed test\r\n",
    "print(f\"Welch's t-test: statistic = {t_Welch}, pvalue = {p_Welch}\")\r\n",
    "\r\n",
    "t_Student, p_Student = ss.ttest_ind(ar1, ar2, equal_var=True) # default to two-tailed test\r\n",
    "print(f\"Student's t-test: statistic = {t_Student}, pvalue = {p_Student}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Welch's t-test: statistic = -5.143878201186483, pvalue = 7.072288064264301e-07\n",
      "Student's t-test: statistic = -5.143878201186483, pvalue = 7.055312345768804e-07\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### T-test Formulation (manual calculation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "n1, n2 = len(ar1), len(ar2)\r\n",
    "m1, m2 = ar1.mean(), ar2.mean()\r\n",
    "var1, var2  = ar1.var(ddof=1), ar2.var(ddof=1)\r\n",
    "\r\n",
    "dof = (var1/n1 + var2/n2)**2 / ((var1**2)/(n1**2)/(n1-1) + (var2**2)/(n2**2)/(n2-1))\r\n",
    "print(f\"degree of freedom = {dof}\")\r\n",
    "\r\n",
    "t_Welch_manual = (m1 - m2) / np.sqrt(var1/n1 + var2/n2)\r\n",
    "p_Welch_manual = ss.t.sf(abs(t_Welch_manual), df=dof)*2\r\n",
    "print(f\"Welch's t-test: statistic = {t_Welch_manual}, pvalue = {p_Welch_manual}\")\r\n",
    "\r\n",
    "t_Student_manual = (m1 - m2)/ (np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2)) * np.sqrt(1/n1 + 1/n2))\r\n",
    "p_Student_manual = ss.t.sf(abs(t_Student_manual), df=dof)*2\r\n",
    "print(f\"Student's t-test: statistic = {t_Student_manual}, pvalue = {p_Student_manual}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "degree of freedom = 177.51519061571628\n",
      "Welch's t-test: statistic = -5.143878201186483, pvalue = 7.072288064264301e-07\n",
      "Student's t-test: statistic = -5.143878201186483, pvalue = 7.072288064264301e-07\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statistical Power"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "std = np.sqrt((var1+var2)/2)\r\n",
    "effect_size = np.abs((m2 - m1) / std)\r\n",
    "ratio = n2 / n1\r\n",
    "\r\n",
    "# Use statsmodels\r\n",
    "analysis = sms.TTestIndPower()\r\n",
    "power = analysis.power(effect_size, n1, ratio, dof, alternative='two-sided')\r\n",
    "\r\n",
    "# Manual calculation\r\n",
    "x = np.abs(m1-m2) / np.sqrt(var1/n1 + var2/n2) - t_Student_manual\r\n",
    "power_manual = ss.t.cdf(x, dof)\r\n",
    "\r\n",
    "print(f\"Statistical Power = {power}; manually calculated = {power_manual}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistical Power = 1.0; manually calculated = 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Theoretical Minimum Number of Samples Required\r\n",
    "Benchmark: *https://www.stat.ubc.ca/~rollin/stats/ssize/n2.html*\r\n",
    "\r\n",
    "Yang Xi: I would prefer to use 2 times of this number."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "m1, std1 = 0.15, 0.05 # measured\r\n",
    "m2, std2 = 0.18, 0.05 # expected\r\n",
    "alpha, power = 0.05, 0.8 # required\r\n",
    "ratio = 1 # required; ratio = n2 / n1\r\n",
    "\r\n",
    "# Use statsmodels\r\n",
    "std = np.sqrt((std1**2 + std2**2)/2)\r\n",
    "effect_size = np.abs((m2 - m1) / std)\r\n",
    "n1 = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, ratio=ratio, alternative='two-sided')\r\n",
    "\r\n",
    "# Manual\r\n",
    "n1_manual = (std1**2 + std2**2) * (ss.norm.ppf(1-alpha/2) + ss.norm.ppf(power))**2 / (m1-m2)**2\r\n",
    "\r\n",
    "print(f\"n1 = {n1}, n2 = {n1*ratio}; manually calculated n1 = {n1_manual}, n2 = {n1_manual*ratio}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n1 = 44.5857902590805, n2 = 44.5857902590805; manually calculated n1 = 43.604887413050506, n2 = 43.604887413050506\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binomial Distribution\r\n",
    "Binomal Distribution can be observed in data like **\"conversion rate\"** (converted / not converted).\r\n",
    "- **Null hypothesis**: two proportions are equal (p1 = p2)\r\n",
    "- **Fisher's exact test** (standard): Can be applied for all sample sizes.\r\n",
    "- **Chi-square test of independence** (alternative): An alternative when numbers in the contingency table are large.\r\n",
    "- **Barnard's test** (alternative): Claimed to work better for 2x2 contingency tables, but for larger tables, the computation increases and the pwoer advantage decreases.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "np.random.seed(0)\r\n",
    "p1, p2 = 0.15, 0.18\r\n",
    "q1, q2 = 1-p1, 1-p2\r\n",
    "ar1 = np.random.choice([0,1], size=4800, p=[q1, p1])\r\n",
    "ar2 = np.random.choice([0,1], size=4800, p=[q2, p2])\r\n",
    "\r\n",
    "contingency_table = np.array([[(ar1==1).sum(),(ar2==1).sum()],[(ar1==0).sum(), (ar2==0).sum()]])\r\n",
    "print(contingency_table)\r\n",
    "\r\n",
    "perior_odds_ratio, p_fisher = ss.fisher_exact(contingency_table, alternative='two-sided')\r\n",
    "print(f\"Fisher's exact test: perior odds ratio = {perior_odds_ratio}, pvalue = {p_fisher}\")\r\n",
    "\r\n",
    "chi2, p_chi2, dof, expected = ss.chi2_contingency(contingency_table, correction=False) # Pearson's chi-squared by default\r\n",
    "## degrees of freedom (dof) = (rows-1) * (cols-1)\r\n",
    "print(f\"Chi-square test: chi2 = {chi2}, pvalue = {p_chi2}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 723  816]\n",
      " [4077 3984]]\n",
      "Fisher's exact test: perior odds ratio = 0.8658182919967103, pvalue = 0.01047388250523832\n",
      "Chi-square test: chi2 = 6.6928268444339984, pvalue = 0.009680159093701474\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statistical Power"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "n1, n2 = len(ar1), len(ar2)\r\n",
    "alpha = p_fisher\r\n",
    "\r\n",
    "ratio = n2/n1\r\n",
    "p_bar = (p1 + ratio*p2) / (1 + ratio)\r\n",
    "q_bar = 1 - p_bar\r\n",
    "\r\n",
    "numerator = np.sqrt(n1*(p1-p2)**2) - np.sqrt(p_bar*q_bar*(1+1/ratio)) * ss.norm.ppf(1-alpha/2)\r\n",
    "denomenator = np.sqrt(p1*q1 + p2*q2/ratio)\r\n",
    "z = numerator/denomenator\r\n",
    "power = ss.norm.cdf(z)\r\n",
    "\r\n",
    "print(f\"Statistical Power = {power}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistical Power = 0.9193746662786612\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Theoretical Minimum Number of Samples Required\r\n",
    "Benchmark: *https://www.stat.ubc.ca/~rollin/stats/ssize/b2.html*\r\n",
    "\r\n",
    "Yang Xi: I would prefer to use 2 times of this number."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "p1 = 0.15 # measured\r\n",
    "p2 = 0.18 # expected\r\n",
    "alpha, power = 0.05, 0.8 # required\r\n",
    "ratio = 1 # required; ratio = n2 / n1\r\n",
    "\r\n",
    "q1, q2 = 1-p1, 1-p2\r\n",
    "p_bar = (p1 + ratio*p2) / (1 + ratio)\r\n",
    "q_bar = 1 - p_bar\r\n",
    "\r\n",
    "numerator = np.sqrt(p_bar*q_bar*(1+1/ratio)) * ss.norm.ppf(1-alpha/2)\r\n",
    "numerator += np.sqrt(p1*q1 + p2*q2/ratio) * ss.norm.ppf(power)\r\n",
    "numerator = numerator**2\r\n",
    "n1 = numerator/(p1-p2)**2\r\n",
    "print(f\"n1 = {n1}; n2 = {n1*ratio}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n1 = 2401.8860715204223; n2 = 2401.8860715204223\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### More on Wikipedia\r\n",
    "The AB Testing page of wikipedia also listed:\r\n",
    "- **Poisson Distribution** (transactions per paying user): E-test or C-test\r\n",
    "- **Multinominal Distribution** (number of each product purchased): chi-squared test\r\n",
    "- **unknown distribution**: Mann-Whitney U test / Gibbs sampling"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "1f2b3eeb8c8c57cc9fbb2de5c20e128904099953a55cc5a227bd47864e28a4ba"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}