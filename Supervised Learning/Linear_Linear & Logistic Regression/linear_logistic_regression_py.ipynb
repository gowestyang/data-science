{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression and Logistic Regression (Python)\n",
    "Yang Xi <br>\n",
    "14 Nov, 2018\n",
    "\n",
    "<br>\n",
    "\n",
    "- Linear Regression: Model Fitting and Interpretation\n",
    "    - Independent Numeric and Categorical Variables\n",
    "    - Response to Highly Correlated Numeric Variables\n",
    "    - Interaction: Numeric Variable Interacts With Boolean Variable\n",
    "    - Polynomial Numeric Variable\n",
    "- Logistic Regression: Classification with Imbalanced Class\n",
    "    - Train Model and Interpret Fitted Coefficients\n",
    "    - Train Performance\n",
    "    - Cross-Validation Performance\n",
    "    - Test Performance\n",
    "- Appendix: Wrap Statsmodels in Sklearn Estimator for Cross-Validation\n",
    "    - Train and Interpret GLM Model\n",
    "    - Train Performance\n",
    "    - Cross-Validation Performance\n",
    "    - Test Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Model Fitting and Interpretation\n",
    "### Independent Numeric and Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = -1.992\n",
      "          coef\n",
      "x2    2.995301\n",
      "x3   -0.003818\n",
      "x1_B  0.995364\n",
      "x1_C  3.001635\n"
     ]
    }
   ],
   "source": [
    "# Simulate data\n",
    "random.seed(1)\n",
    "n = 9000\n",
    "x1 = np.array(['A', 'B', 'C']*int(n/3))\n",
    "x1 = np.random.choice(x1, n, replace=False)\n",
    "x2 = np.random.uniform(0, 2, n)\n",
    "x3 = np.random.uniform(0, 1, n)\n",
    "e = np.random.uniform(-0.5, 0.5, n)\n",
    "\n",
    "b1_map = {'A':-2, 'B':-1, 'C':1} # 0, 1, 3\n",
    "b2 = 3\n",
    "\n",
    "X = pd.DataFrame({'x1':x1, 'x2':x2, 'x3':x3})\n",
    "y = list(map(b1_map.get, x1)) + b2*x2 + e \n",
    "\n",
    "# Covert categorical variable\n",
    "X = pd.get_dummies(X, columns=['x1'], drop_first=True) # x2, x3, x1_B, x1_C\n",
    "\n",
    "# Fit model\n",
    "lmFit = lm().fit(X, y)\n",
    "print('intercept = {0:.3f}'.format(lmFit.intercept_))\n",
    "print(pd.DataFrame(lmFit.coef_, index=X.columns, columns=['coef']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**statsmodels** package can provide more statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.982\n",
      "Model:                            OLS   Adj. R-squared:                  0.982\n",
      "Method:                 Least Squares   F-statistic:                 1.230e+05\n",
      "Date:                Fri, 17 Jul 2020   Prob (F-statistic):               0.00\n",
      "Time:                        13:21:32   Log-Likelihood:                -1592.5\n",
      "No. Observations:                9000   AIC:                             3195.\n",
      "Df Residuals:                    8995   BIC:                             3231.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.9920      0.009   -217.799      0.000      -2.010      -1.974\n",
      "x2             2.9953      0.005    567.827      0.000       2.985       3.006\n",
      "x3            -0.0038      0.011     -0.360      0.719      -0.025       0.017\n",
      "x1_B           0.9954      0.007    133.439      0.000       0.981       1.010\n",
      "x1_C           3.0016      0.007    402.397      0.000       2.987       3.016\n",
      "==============================================================================\n",
      "Omnibus:                     7768.854   Durbin-Watson:                   1.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              539.508\n",
      "Skew:                          -0.003   Prob(JB):                    7.04e-118\n",
      "Kurtosis:                       1.801   Cond. No.                         6.87\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "Xc = sm.add_constant(X)\n",
    "sm_fit = sm.OLS(y, Xc).fit()\n",
    "print(sm_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response to Highly Correlated Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = -0.023\n",
      "        coef\n",
      "x1  2.506362\n",
      "x2  2.506362\n"
     ]
    }
   ],
   "source": [
    "# Simulate data\n",
    "random.seed(1)\n",
    "n = 10000\n",
    "x1 = np.random.uniform(1, 2, n)\n",
    "x2 = x1\n",
    "e = np.random.uniform(-0.5, 0.5, n)\n",
    "\n",
    "b1 = 2\n",
    "b2 = 3\n",
    "\n",
    "X = pd.DataFrame({'x1':x1, 'x2':x2})\n",
    "y = b1*x1 + b2*x2 + e\n",
    "\n",
    "# Fit model\n",
    "lmFit = lm().fit(X, y)\n",
    "print('intercept = {0:.3f}'.format(lmFit.intercept_))\n",
    "print(pd.DataFrame(lmFit.coef_, index=X.columns, columns=['coef']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction: Numeric Variable Interacts with Boolean Variable\n",
    "Take note on how to interpret the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = 0.001\n",
      "             coef\n",
      "x2      -2.003585\n",
      "x1_Y    -0.002665\n",
      "x1_Y:x2  3.004301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures as poly\n",
    "\n",
    "# Simulate data\n",
    "random.seed(1)\n",
    "n = 10000\n",
    "x1 = np.array(['N','Y']*int(n/2))\n",
    "x1 = np.random.choice(x1, n, replace=False)\n",
    "x2 = np.random.uniform(0, 1, n)\n",
    "e = np.random.uniform(-0.1, 0.1, n)\n",
    "\n",
    "bn = -2\n",
    "by = 1\n",
    "\n",
    "# Covert categorical variable\n",
    "X = pd.DataFrame({'x1':x1, 'x2':x2})\n",
    "X = pd.get_dummies(X, columns=['x1'], drop_first=True)  # x2, x1_Y\n",
    "\n",
    "# Interaction\n",
    "X = pd.DataFrame(poly(interaction_only=True, include_bias=False).fit_transform(X),\n",
    "                 columns=np.append(X.columns.values, 'x1_Y:x2')) # x2, x1_Y, x2:x1_Y\n",
    "\n",
    "y = np.where(x1=='N', bn*x2, by*x2) + e\n",
    "\n",
    "# Fit model\n",
    "lmFit = lm().fit(X, y)\n",
    "print('intercept = {0:.3f}'.format(lmFit.intercept_))\n",
    "print(pd.DataFrame(lmFit.coef_, index=X.columns, columns=['coef']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Numeric Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = 0.047\n",
      "          coef\n",
      "x1    1.967578\n",
      "x1^2  3.005012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures as poly\n",
    "\n",
    "# Simulate data\n",
    "random.seed(1)\n",
    "n = 10000\n",
    "x1 = np.random.uniform(2, 5, n)\n",
    "e = np.random.uniform(-0.5, 0.5, n)\n",
    "\n",
    "b1 = 2\n",
    "b2 = 3\n",
    "\n",
    "xPoly = poly(2, include_bias=False).fit_transform(np.array([[x, 1] for x in x1]))\n",
    "X = pd.DataFrame(np.array([v[[0,2]] for v in xPoly]),\n",
    "                 columns=['x1', 'x1^2'])\n",
    "\n",
    "y = b2*X['x1^2'] + b1*X['x1'] + e\n",
    "\n",
    "# Fit model\n",
    "lmFit = lm().fit(X, y)\n",
    "print('intercept = {0:.3f}'.format(lmFit.intercept_))\n",
    "print(pd.DataFrame(lmFit.coef_, index=X.columns, columns=['coef']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Classification with Imbalanced Class\n",
    "### Train Model and Interpret Fitted Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = -0.345\n",
      "                            coef\n",
      "CreditLimit            -0.000002\n",
      "Age                     0.004691\n",
      "SepBill                -0.000004\n",
      "AugBill                 0.000005\n",
      "SepPay                 -0.000014\n",
      "AugPay                 -0.000007\n",
      "Sex_M                   0.153457\n",
      "Marriage_single        -0.164347\n",
      "Education_graduate      0.032429\n",
      "Education_university    0.040215\n",
      "SepRepayment_1m delay   1.076591\n",
      "SepRepayment_2m+ delay  2.528001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "dfTrain0 = pd.read_csv(\"../../data/(2016 UCI) Credit Default/data_train.csv\")\n",
    "dfTest0 = pd.read_csv(\"../../data/(2016 UCI) Credit Default/data_test.csv\")\n",
    "\n",
    "def prepTrainTest(df):\n",
    "    df = pd.get_dummies(df, columns=['Sex', 'Marriage'], drop_first=True)\n",
    "    df = pd.get_dummies(df, columns=['Education', 'SepRepayment']).drop(['Education_high school', 'SepRepayment_paid'], axis=1)\n",
    "    df['Default'] = df['Default']==1\n",
    "    return df\n",
    "dfTrain = prepTrainTest(dfTrain0)\n",
    "XTrain = dfTrain.drop('Default',axis=1)\n",
    "yTrain = dfTrain['Default']\n",
    "\n",
    "# Fit model\n",
    "## Note: LogisticRegression() forces L1 or L2 regularization. To remove regularization,\n",
    "## need to set penalty to 'l1' and C to a large value.\n",
    "lmModel = LogisticRegression(class_weight=\"balanced\", penalty='l1', C=1000)\n",
    "lmFit = lmModel.fit(XTrain, yTrain)\n",
    "print('intercept = {0:.3f}'.format(lmFit.intercept_[0]))\n",
    "print(pd.DataFrame(lmFit.coef_.T, index=XTrain.columns, columns=['coef']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pred0  pred1\n",
      "actual0  15530   2590\n",
      "actual1   2496   2716\n",
      "      F1    AUC\n",
      "0  0.516  0.749\n"
     ]
    }
   ],
   "source": [
    "probTrain = [x[1] for x in lmFit.predict_proba(XTrain)]\n",
    "predTrain = lmFit.predict(XTrain)\n",
    "\n",
    "cmTrain = pd.DataFrame(confusion_matrix(yTrain, predTrain))\n",
    "cmTrain.columns = pd.Series(cmTrain.columns).apply(lambda s: 'pred'+str(s))\n",
    "cmTrain.index = pd.Series(cmTrain.index).apply(lambda s: 'actual'+str(s))\n",
    "print(cmTrain)\n",
    "\n",
    "perfTrain = pd.DataFrame({'F1':[round(f1_score(yTrain, predTrain), 3)],\n",
    "                          'AUC':[round(roc_auc_score(yTrain, probTrain),3)]})\n",
    "print(perfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation f1 score is 0.517\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lmModel, XTrain, yTrain, scoring='f1', cv=10)\n",
    "\n",
    "print('Cross-validation f1 score is {0:.3f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pred0  pred1\n",
      "actual0   3876    653\n",
      "actual1    638    664\n",
      "Test f1 score = 0.507\n"
     ]
    }
   ],
   "source": [
    "dfTest = prepTrainTest(dfTest0)\n",
    "XTest = dfTest.drop('Default',axis=1)\n",
    "yTest = dfTest['Default']\n",
    "    \n",
    "predTest = lmFit.predict(XTest)\n",
    "\n",
    "cmTest = pd.DataFrame(confusion_matrix(yTest, predTest))\n",
    "cmTest.columns = pd.Series(cmTest.columns).apply(lambda s: 'pred'+str(s))\n",
    "cmTest.index = pd.Series(cmTest.index).apply(lambda s: 'actual'+str(s))\n",
    "print(cmTest)\n",
    "\n",
    "f1Test = f1_score(yTest, predTest)\n",
    "print('Test f1 score = {0:.3f}'.format(f1Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Wrap Statsmodels in Sklearn Estimator for Cross-Validation\n",
    "`sklearn.model_selection.cross_val_score` can be used to carry out cross-validation of customized model.<br>\n",
    "This section will demonstrate how to wrap the `GLM` model from `statsmodels` pakcage with sklearn estimator.\n",
    "### Train and Interpret GLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                    -0.345101\n",
       "CreditLimit              -0.000002\n",
       "Age                       0.004696\n",
       "SepBill                  -0.000004\n",
       "AugBill                   0.000005\n",
       "SepPay                   -0.000014\n",
       "AugPay                   -0.000007\n",
       "Sex_M                     0.153460\n",
       "Marriage_single          -0.164295\n",
       "Education_graduate        0.032478\n",
       "Education_university      0.040273\n",
       "SepRepayment_1m delay     1.076577\n",
       "SepRepayment_2m+ delay    2.527989\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "dfTrain0 = pd.read_csv(\"../../data/(2016 UCI) Credit Default/data_train.csv\")\n",
    "dfTest0 = pd.read_csv(\"../../data/(2016 UCI) Credit Default/data_test.csv\")\n",
    "\n",
    "def prepTrainTest(df):\n",
    "    df = pd.get_dummies(df, columns=['Sex', 'Marriage'], drop_first=True)\n",
    "    df = pd.get_dummies(df, columns=['Education', 'SepRepayment']).drop(['Education_high school', 'SepRepayment_paid'], axis=1)\n",
    "    df['Default'] = df['Default']==1\n",
    "    return df\n",
    "dfTrain = prepTrainTest(dfTrain0)\n",
    "XTrain = dfTrain.drop('Default',axis=1)\n",
    "yTrain = dfTrain['Default']\n",
    "XTrain = sm.add_constant(XTrain)\n",
    "\n",
    "w = sum(yTrain==0)/sum(yTrain==1)\n",
    "yWeights = yTrain.apply(lambda x: w if x==1 else 1)\n",
    "\n",
    "# Fit model\n",
    "lmModel = sm.GLM(yTrain, XTrain, family=sm.families.Binomial(), freq_weights=yWeights)\n",
    "lmFit = lmModel.fit()\n",
    "lmFit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pred0  pred1\n",
      "actual0  15530   2590\n",
      "actual1   2496   2716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.5118733509234829,\n",
       " 'recall': 0.5211051419800461,\n",
       " 'f1-score': 0.5164479939151929,\n",
       " 'support': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probTrain = lmFit.predict(XTrain)\n",
    "predTrain = probTrain.apply(lambda x: 0 if x<0.5 else 1)\n",
    "\n",
    "cmTrain = pd.DataFrame(confusion_matrix(yTrain, predTrain))\n",
    "cmTrain.columns = pd.Series(cmTrain.columns).apply(lambda s: 'pred'+str(s))\n",
    "cmTrain.index = pd.Series(cmTrain.index).apply(lambda s: 'actual'+str(s))\n",
    "print(cmTrain)\n",
    "\n",
    "prfsTrain = precision_recall_fscore_support(yTrain, predTrain, average='binary', pos_label=1)\n",
    "prfsTrain = {\"precision\": prfsTrain[0],\n",
    "             \"recall\": prfsTrain[1],\n",
    "             \"f1-score\": prfsTrain[2],\n",
    "             \"support\": prfsTrain[3]}\n",
    "prfsTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Performance\n",
    "Here we will wrap `statsmodels.api.GLM` model in `sklearn.model_selection.cross_val_score` to perform 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation f1 score is 0.517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class LogisticsRegression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        ys = y.unique()\n",
    "        ys.sort()\n",
    "        w = sum(y==ys[0])/sum(y==ys[1])\n",
    "        yWegiths = y.apply(lambda x: w if x==ys[1] else 1)\n",
    "        self.fitted = sm.GLM(y, X, family=sm.families.Binomial(), freq_weights=yWegiths).fit()   \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prob = self.fitted.predict(X)\n",
    "        pred = prob.apply(lambda x: 0 if x<0.5 else 1)\n",
    "        return pred\n",
    "\n",
    "scores = cross_val_score(LogisticsRegression(), XTrain, yTrain, scoring='f1', cv=10)\n",
    "\n",
    "print('Cross-validation f1 score is {0:.3f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pred0  pred1\n",
      "actual0   3876    653\n",
      "actual1    638    664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.5041761579347,\n",
       " 'recall': 0.5099846390168971,\n",
       " 'f1-score': 0.5070637647957236,\n",
       " 'support': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest = prepTrainTest(dfTest0)\n",
    "XTest = dfTest.drop('Default',axis=1)\n",
    "yTest = dfTest['Default']\n",
    "XTest = sm.add_constant(XTest)\n",
    "    \n",
    "probTest = lmFit.predict(XTest)\n",
    "predTest = probTest.apply(lambda x: 0 if x<0.5 else 1)\n",
    "\n",
    "cmTest = pd.DataFrame(confusion_matrix(yTest, predTest))\n",
    "cmTest.columns = pd.Series(cmTest.columns).apply(lambda s: 'pred'+str(s))\n",
    "cmTest.index = pd.Series(cmTest.index).apply(lambda s: 'actual'+str(s))\n",
    "print(cmTest)\n",
    "\n",
    "prfsTest = precision_recall_fscore_support(yTest, predTest, average='binary', pos_label=1)\n",
    "prfsTest = {\"precision\": prfsTest[0],\n",
    "             \"recall\": prfsTest[1],\n",
    "             \"f1-score\": prfsTest[2],\n",
    "             \"support\": prfsTest[3]}\n",
    "prfsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
