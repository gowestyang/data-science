---
title: "Random Forest (R)"
author: "Yang Xi"
date: "22 Nov, 2018"
output:
  html_document:
    toc: 1
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

<br>

# Example: Classification with Imbalanced Class
```{r, message=FALSE}
library(tidyverse)
library(caret)
library(MLmetrics)
library(ROCR)

dfTrain0 <- read_csv("../../data/(2016 UCI) Credit Default/data_train.csv")
dfTest0 <- read_csv("../../data/(2016 UCI) Credit Default/data_test.csv")

```

<br>**Preprocessing**
```{r}
PrepTrainTest <- function(df) {
  df %>%
    mutate(Education = relevel(as.factor(Education), ref="high school"),
           SepRepayment = relevel(as.factor(SepRepayment), ref="paid"),
           Default = relevel(as.factor(ifelse(Default==0, "N", "Y")), ref="N"))
}
dfTrain <- PrepTrainTest(dfTrain0)

yTrain <- dfTrain$Default
w0 <- 1
w1 <- sum(yTrain=="N")/sum(yTrain=="Y")
```

<br>

## Tune Optimal Parameters Through Cross-Validation
**Note:**

* Handling class weights in `randomForest()` module is tricky, so `ranger` module will be used.
* Number of estimators `num.trees` in random forest is usually in scale of hundreds. It is commonly tuned first, while I will skip tuning this parameter and use a fixed number instead.
* Here I will tune *number of features to sample* `mtry` and *minimum number of observations on single node* `min.node.size`
  + `mtry` is usually default to *floor(number of features/3)*
  + `min.node.size` can lead to strong overfitting if too small

```{r}
f1 <- function(data, lev = NULL, model = "F1") {
  c(F1 = F1_Score(data$obs, data$pred, positive = lev[2]))
}

rfFitCV <- train(Default ~., dfTrain, method="ranger",
                 class.weights = c(w0, w1),
                 num.trees = 500, importance = "impurity",
                 metric = "F1",
                 trControl = trainControl(method = "cv", # 10 fold by default
                                          summaryFunction = f1,
                                          verboseIter = F), # verboseIter to on/off status
                 tuneGrid = expand.grid(splitrule="gini",
                                        mtry=seq(floor(ncol(dfTrain)/3), (ncol(dfTrain)-1), 2),
                                        min.node.size=floor(seq(nrow(dfTrain)/40, nrow(dfTrain)/10, length.out=4))))

# optimal parameters and CV performance
tuneResults <- rfFitCV$results %>%
  select(mtry, min.node.size, F1, F1SD)

ggplot(tuneResults, aes(x=mtry, y=min.node.size, fill=F1)) + 
  geom_tile() + 
  scale_fill_gradient(low="red", high="green")

mtryOp <- rfFitCV$bestTune$mtry
nodeOp <- rfFitCV$bestTune$min.node.size

filter(tuneResults,
       mtry==mtryOp,
       min.node.size==nodeOp)
```

<br>

## Train Performance
Fit a new model with optimized parameters.
```{r}
library(ranger)

rfFit <- ranger(Default ~., dfTrain,
                case.weights = ifelse(dfTrain$Default=="N", w0, w1),
                num.trees = 500, importance = "impurity", probability = T,
                splitrule = "gini", mtry = mtryOp, min.node.size = nodeOp)

probTrain <- predict(rfFit, dfTrain)$predictions[, "Y"]
predTrain <- as.factor(ifelse(probTrain < 0.5, "N", "Y"))

cmTrain <- confusionMatrix(predTrain, yTrain, positive="Y")
cmTrain

perfTrain <- data.frame(F1 = round(cmTrain$byClass['F1'], 3),
                        AUC = round(performance(prediction(probTrain, yTrain),
                                                measure="auc")@y.values[[1]], 3))
row.names(perfTrain) <- NULL
perfTrain
```

<br>

## Variable Importance and Partial Plots
**Variable Importance**
```{r}
rfVarImp <- data.frame(importance(rfFit))
rfVarImp$variable <- row.names(rfVarImp)
rfVarImp %>% select(variable, importance=importance.rfFit.) %>% arrange(desc(importance))
```

<br>**Partial Plots of `SepRepayment` and `CreditLimit`**
```{r}
library(pdp)

pdpSepRepayment <- partial(rfFit, pred.var = "SepRepayment", plot = TRUE, train = dfTrain)
pdpCreditLimit <- partial(rfFit, pred.var = "CreditLimit", plot = TRUE, train = dfTrain)

grid.arrange(
  pdpSepRepayment,
  pdpCreditLimit,
  ncol = 2
)
```

<br>

## Test Performance
```{r}
dfTest <- PrepTrainTest(dfTest0)
probTest <- predict(rfFit, dfTest)$predictions[, "Y"]
predTest <- as.factor(ifelse(probTest < 0.5, "N", "Y"))

cmTest <- confusionMatrix(predTest, dfTest$Default, positive="Y")
cmTest

paste('Test F1 score is', round(cmTest$byClass['F1'], 3))
```
